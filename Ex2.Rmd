---
title: "MO911A -- Resolução do Exercício 2"
author: "Décio Luiz Gazzoni Filho (RA264965), Vitor Satoru Machi Matsumine (RA264962)"
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Intervalo de confiança

Inicialmente importou-se os dados do arquivo `.csv` fornecido, que foram categorizados (como diabético ou não) para posterior análise.

```{r}
mydata = read.csv("ex1.csv")
mydata$type <- as.factor(mydata$type)
```

Os dados foram separados em duas variáveis `data_yes` e `data_no`, referindo-se a pacientes diabéticos ou não.

```{r}
data_yes = mydata$bp[mydata$type == "Yes"]
data_no = mydata$bp[mydata$type == "No"]
```

Na sequência, foram calculados os intervalos de confiança de cada conjunto de dados usando cada um dos métodos solicitados. Inicialmente, temos o teste $t$:

```{r}
(t.ci.yes = t.test(data_yes)$conf.int[1:2])
(t.ci.no = t.test(data_no)$conf.int[1:2])
```

Em seguida, para o teste Wilcoxon rank-sum:

```{r}
(w.ci.yes = wilcox.test(data_yes,conf.int=TRUE)$conf.int[1:2])
(w.ci.no = wilcox.test(data_no,conf.int=TRUE)$conf.int[1:2])
```

Por fim, usou-se o método bootstrap. Para tanto, é necessário importar uma biblioteca e definir uma função para cálculo da média:

```{r}
library(boot)
auxf <- function(dado,indice){
  return(mean(dado[indice]))
}
```

Calculando então o intervalo de confiança pelo método bootstrap, primeiro para pacientes diabéticos:

```{r}
bb_yes = boot(data_yes,R=5000, statistic=auxf)
(b.yes.ci = boot.ci(bb_yes,type="bca")$bca[1,4:5])
```

Repetindo o cálculo para pacientes não-diabéticos:

```{r}
bb_no = boot(data_no,R=5000, statistic=auxf)
(b.no.ci = boot.ci(bb_no,type="bca")$bca[1,4:5])
```

Para melhor visualização,construiu-se uma tabela comparativa dos intervalos de confiança:

```{r echo=FALSE}
library(knitr)
rownames <- c("Diabéticos", "Não-diabéticos")
colnames <- c("Teste $t$", "Wilcoxon", "Bootstrap")
ci <- array("", dim=c(2,3), dimnames = list(rownames,colnames))
ci[1,1] = paste(format(t.ci.yes, nsmall=5), collapse=",")
ci[2,1] = paste(format(t.ci.no, nsmall=5), collapse=",")
ci[1,2] = paste(format(w.ci.yes, nsmall=5), collapse=",")
ci[2,2] = paste(format(w.ci.no, nsmall=5), collapse=",")
ci[1,3] = paste(format(b.yes.ci, nsmall=5), collapse=",")
ci[2,3] = paste(format(b.no.ci, nsmall=5), collapse=",")
kable(ci)
```


## Interseção dos intervalos de confiança

Tomando como exemplo o teste Wilcoxon rank-sum, repetimos os intervalos de confiança para referência:

```{r}
w.ci.yes
w.ci.no
```

Observa-se que não há intersecção entre os dois intervalos de confiança, uma vez que, a pressão média dos pacientes diabéticos (`r mean(data_yes)`) é maior do que a dos pacientes não diabéticos (`r mean(data_no)`) e o limite inferior de pressão dos pacientes diabéticos (`r w.ci.yes[1]`) é maior que o limite superior da pressão dos pacientes não-diabéticos (`r w.ci.no[2]`).

Espera-se, portanto, que o teste resulte em uma diferença estatisticamente significativa entre os dois conjuntos dos dados. Isso é verificado pela execução do teste de Wilcox para os dois conjuntos de dados:

```{r}
(w.test = wilcox.test(data_yes, data_no))
```

De fato, $p = `r w.test$p.value` < 0.05$, e portanto a diferença é estatisticamente significativa.


## Tamanho de efeito

Usando a biblioteca `effsize`, foi calculado o Cohen D com pooled standard deviation (usando o parâmetro `pooled=TRUE` da função `cohen.d`, conforme informado na documentação):

```{r}
library(effsize)
cohen_d = cohen.d(data_yes, data_no, pooled=TRUE)
cohen_d$estimate
```

O valor do Cohen D é `r cohen_d$estimate`, o que indica um tamanho de efeito de pequeno a médio, conforme classificação de Cohen. Porém, conforme afirmado na aula, mesmo um efeito de 0.2 não pode ser considerado pequeno, a despeito de esta ser a classificação inicial proposta por Cohen.


## Intervalo de confiança para o tamanho de efeito

Do cálculo previamente realizado do Cohen D, pode-se extrair um intervalo de confiança:

```{r}
cohen_d$conf.int
```

Observa-se que esse intervalo de confiança não cruza o zero, portanto, pode-se afirmar que existe uma diferença significativa entre os dois conjuntos de dados.